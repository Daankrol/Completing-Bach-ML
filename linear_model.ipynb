{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from window_generator import WindowGenerator\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from read_data import *\n",
    "\n",
    "MAX_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_and_fit(model, window, patience=2, verbose=2):\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                      patience=patience,\n",
    "                                                      mode='min')\n",
    "\n",
    "    model.compile(loss=tf.losses.MeanSquaredError(),\n",
    "                  optimizer=tf.optimizers.Adam(),\n",
    "                  metrics=[tf.metrics.MeanAbsoluteError()])\n",
    "\n",
    "# At the end of each epoch, the model will iterate over the validation dataset and compute the validation loss and validation metrics.\n",
    "    history = model.fit(window.train, epochs=MAX_EPOCHS,\n",
    "                        validation_data=window.val,\n",
    "                        callbacks=[early_stopping],\n",
    "                        verbose=verbose)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs shape (batch, time, features): (32, 6, 6)\n",
      "Labels shape (batch, time, features): (32, 1, 22)\n",
      "<MapDataset shapes: ((None, 6, 6), (None, 1, 22)), types: (tf.float32, tf.float32)>\n"
     ]
    }
   ],
   "source": [
    "multi_step_window = WindowGenerator(input_width=6, label_width=1, shift=1)\n",
    "\n",
    "for example_inputs, example_labels in multi_step_window.train.take(1):\n",
    "    print(f\"Inputs shape (batch, time, features): {example_inputs.shape}\")\n",
    "    print(f\"Labels shape (batch, time, features): {example_labels.shape}\")\n",
    "\n",
    "print(multi_step_window.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (32, 6, 6)\n",
      "Output shape: (32, 6, 22)\n"
     ]
    }
   ],
   "source": [
    "linear = tf.keras.Sequential(\n",
    "    [tf.keras.layers.Dense(22, activation=\"softmax\")])\n",
    "print('Input shape:', multi_step_window.example[0].shape)\n",
    "print('Output shape:', linear(multi_step_window.example[0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (32, 6, 6)\n",
      "Output shape: (32, 1, 22)\n"
     ]
    }
   ],
   "source": [
    "linear_multi_step = tf.keras.Sequential([\n",
    "    # Shape: (time, features) => (time*features)\n",
    "    tf.keras.layers.Flatten(),\n",
    "#     tf.keras.layers.Dense(units=32, activation='relu'),\n",
    "#     tf.keras.layers.Dense(units=32, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=22, activation='softmax'),\n",
    "    # Add back the time dimension.\n",
    "    # Shape: (outputs) => (1, outputs)\n",
    "    tf.keras.layers.Reshape([1, -1]),\n",
    "])\n",
    "print('Input shape:', multi_step_window.example[0].shape)\n",
    "print('Output shape:', linear_multi_step(multi_step_window.example[0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.0169, mean_absolute_error: 0.0377, val_loss: 0.0210, val_mean_absolute_error: 0.0432\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = compile_and_fit(linear_multi_step, multi_step_window, verbose=0)\n",
    "print(\n",
    "    \"loss: {:0.4f}, mean_absolute_error: {:0.4f}, val_loss: {:0.4f}, val_mean_absolute_error: {:0.4f}\".format(\n",
    "        history.history[\"loss\"][-1],\n",
    "        history.history[\"mean_absolute_error\"][-1],\n",
    "        history.history[\"val_loss\"][-1],\n",
    "        history.history[\"val_mean_absolute_error\"][-1],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0263 - mean_absolute_error: 0.0495\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.02626441791653633, 'mean_absolute_error': 0.049481768161058426}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "print(\"Evaluate\")\n",
    "result = linear_multi_step.evaluate(multi_step_window.test)\n",
    "dict(zip(linear_multi_step.metrics_names, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Get last window \n",
    "last_window = None\n",
    "last_pitch = None\n",
    "all_predicted_pitches = []\n",
    "\n",
    "for i in range(100):\n",
    "    if last_window is None:\n",
    "        for inputs, labels in multi_step_window.test_no_shuffle.as_numpy_iterator():\n",
    "            pass\n",
    "\n",
    "#     print('window:', type(inputs),inputs ,'\\n====\\nlabels', labels)\n",
    "#     print('window shape:', inputs.shape, ' label shape:', labels.shape)\n",
    "\n",
    "    # Model is expecting a shape of (batch, timestep, features) but for one sample this is (6,6)\n",
    "    # Add dimension to input\n",
    "    probabilities = linear_multi_step.predict( np.array([inputs]))[0]\n",
    "    probabilities = probabilities[0]\n",
    "    predicted_pitch = get_pitch_from_probability(probabilities, key=multi_step_window.pitch_conversion_key)\n",
    "    all_predicted_pitches.append(predicted_pitch)\n",
    "    features = get_pitch_features(predicted_pitch)\n",
    "\n",
    "    if last_pitch is None:\n",
    "        last_pitch = get_voice(0)[-1]\n",
    "\n",
    "    # - find new duration based on previous and current pitch\n",
    "    if last_pitch == predicted_pitch:\n",
    "        duration = multi_step_window.df.iloc[-1]['dur'] + 1 \n",
    "    else:\n",
    "        duration = 1\n",
    "        \n",
    "    last_pitch = predicted_pitch\n",
    "\n",
    "    # create new dataframe\n",
    "    new_df = pd.DataFrame(data={'dur': duration}, dtype=float, index=[0])\n",
    "    new_df['log_pitch'], new_df['chroma_x'], new_df['chroma_y'], new_df['c5_x'], new_df['c5_y'] = features\n",
    "    # - Normalise features\n",
    "    new_df = (new_df - multi_step_window.train_mean) / multi_step_window.train_std\n",
    "    # - Make new window based on previous timesteps with a slide of 1 and the normalised features\n",
    "    last_window = np.append(inputs[1:], new_df.values.tolist(), axis=0)\n",
    "\n",
    "print(all_predicted_pitches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
