{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from window_generator import WindowGenerator\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from read_data import *\n",
    "from methods import *\n",
    "MAX_EPOCHS = 20\n",
    "VOICE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_and_fit(model, window, patience=2, verbose=0):\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                      patience=patience,\n",
    "                                                      mode='min',\n",
    "                                                     restore_best_weights=True)\n",
    "#  Early stopping when there is no improvement in loss. \n",
    "    model.compile(loss=tf.losses.CategoricalCrossentropy(),\n",
    "                  optimizer=tf.optimizers.Adam(),\n",
    "                  metrics=[tf.metrics.CategoricalAccuracy(), tf.metrics.CategoricalCrossentropy(),tf.metrics.MeanAbsoluteError()])\n",
    "\n",
    "# At the end of each epoch, the model will iterate over the validation dataset and compute the validation loss and validation metrics.\n",
    "    history = model.fit(window.train, epochs=MAX_EPOCHS,\n",
    "                        validation_data=window.val,\n",
    "                        callbacks=[early_stopping],\n",
    "                        verbose=verbose)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs shape (batch, time, features): (1, 54, 6)\n",
      "Labels shape (batch, time, features): (1, 1, 23)\n",
      "<TakeDataset shapes: ((None, 54, 6), (None, 1, 23)), types: (tf.float32, tf.float32)>\n"
     ]
    }
   ],
   "source": [
    "multi_step_window = WindowGenerator(input_width=54, label_width=1, shift=1, batch_size=1, voice_number=VOICE)\n",
    "\n",
    "for example_inputs, example_labels in multi_step_window.train.take(1):\n",
    "    print(f\"Inputs shape (batch, time, features): {example_inputs.shape}\")\n",
    "    print(f\"Labels shape (batch, time, features): {example_labels.shape}\")\n",
    "\n",
    "print(multi_step_window.train)\n",
    "# print(len(multi_step_window.label_columns_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (1, 54, 6)\n",
      "Output shape: (1, 1, 23)\n",
      "Epoch 1/20\n",
      "2637/2637 - 4s - loss: 2.7540 - categorical_accuracy: 0.4293 - categorical_crossentropy: 2.7540 - mean_absolute_error: 0.0548 - val_loss: 1.5018 - val_categorical_accuracy: 0.6109 - val_categorical_crossentropy: 1.5018 - val_mean_absolute_error: 0.0453\n",
      "Epoch 2/20\n",
      "2637/2637 - 4s - loss: 1.2850 - categorical_accuracy: 0.6526 - categorical_crossentropy: 1.2850 - mean_absolute_error: 0.0391 - val_loss: 0.9933 - val_categorical_accuracy: 0.7437 - val_categorical_crossentropy: 0.9933 - val_mean_absolute_error: 0.0331\n",
      "Epoch 3/20\n",
      "2637/2637 - 3s - loss: 0.8761 - categorical_accuracy: 0.7584 - categorical_crossentropy: 0.8761 - mean_absolute_error: 0.0298 - val_loss: 0.6893 - val_categorical_accuracy: 0.8021 - val_categorical_crossentropy: 0.6893 - val_mean_absolute_error: 0.0251\n",
      "Epoch 4/20\n",
      "2637/2637 - 3s - loss: 0.6286 - categorical_accuracy: 0.8271 - categorical_crossentropy: 0.6286 - mean_absolute_error: 0.0225 - val_loss: 0.6213 - val_categorical_accuracy: 0.8260 - val_categorical_crossentropy: 0.6213 - val_mean_absolute_error: 0.0219\n",
      "Epoch 5/20\n",
      "2637/2637 - 3s - loss: 0.4958 - categorical_accuracy: 0.8733 - categorical_crossentropy: 0.4958 - mean_absolute_error: 0.0173 - val_loss: 0.5278 - val_categorical_accuracy: 0.8513 - val_categorical_crossentropy: 0.5278 - val_mean_absolute_error: 0.0186\n",
      "Epoch 6/20\n",
      "2637/2637 - 3s - loss: 0.4393 - categorical_accuracy: 0.8874 - categorical_crossentropy: 0.4393 - mean_absolute_error: 0.0149 - val_loss: 0.4386 - val_categorical_accuracy: 0.8778 - val_categorical_crossentropy: 0.4386 - val_mean_absolute_error: 0.0158\n",
      "Epoch 7/20\n",
      "2637/2637 - 3s - loss: 0.3513 - categorical_accuracy: 0.9060 - categorical_crossentropy: 0.3513 - mean_absolute_error: 0.0123 - val_loss: 0.3718 - val_categorical_accuracy: 0.9110 - val_categorical_crossentropy: 0.3718 - val_mean_absolute_error: 0.0119\n",
      "Epoch 8/20\n",
      "2637/2637 - 3s - loss: 0.2995 - categorical_accuracy: 0.9223 - categorical_crossentropy: 0.2995 - mean_absolute_error: 0.0099 - val_loss: 0.3800 - val_categorical_accuracy: 0.9017 - val_categorical_crossentropy: 0.3800 - val_mean_absolute_error: 0.0114\n",
      "Epoch 9/20\n",
      "2637/2637 - 3s - loss: 0.2879 - categorical_accuracy: 0.9283 - categorical_crossentropy: 0.2879 - mean_absolute_error: 0.0088 - val_loss: 0.3898 - val_categorical_accuracy: 0.8884 - val_categorical_crossentropy: 0.3898 - val_mean_absolute_error: 0.0118\n",
      "Note that these are the LAST model metrics and not the BEST model metrics because of early stopping with restore_best_weights \n",
      "epochs: 9, loss: 0.2879, mean_absolute_error: 0.0088, val_loss: 0.3898, val_mean_absolute_error: 0.0118\n",
      "Evaluate\n",
      "376/376 [==============================] - 1s 955us/step - loss: 0.3811 - categorical_accuracy: 0.9096 - categorical_crossentropy: 0.3811 - mean_absolute_error: 0.0125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.3811323344707489,\n",
       " 'categorical_accuracy': 0.9095744490623474,\n",
       " 'categorical_crossentropy': 0.3811323344707489,\n",
       " 'mean_absolute_error': 0.012468373402953148}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_output_nodes = len(multi_step_window.label_columns_indices)\n",
    "\n",
    "initializer = tf.keras.initializers.RandomUniform(minval=-0.50, maxval=0.50)\n",
    "linear_multi_step = tf.keras.Sequential([\n",
    "    # Shape: (time, features) => (time*features)\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=64, kernel_initializer=initializer, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=64, kernel_initializer=initializer, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=n_output_nodes, activation='softmax'),\n",
    "    # Add back the time dimension.\n",
    "    # Shape: (outputs) => (1, outputs)\n",
    "    tf.keras.layers.Reshape([1, -1]),\n",
    "])\n",
    "print('Input shape:', multi_step_window.example[0].shape)\n",
    "print('Output shape:', linear_multi_step(multi_step_window.example[0]).shape)\n",
    "\n",
    "# Train the model\n",
    "history = compile_and_fit(linear_multi_step, multi_step_window, verbose=2)\n",
    "\n",
    "print('Note that these are the LAST model metrics and not the BEST model metrics because of early stopping with restore_best_weights ')\n",
    "print(\n",
    "    \"epochs: {}, loss: {:0.4f}, mean_absolute_error: {:0.4f}, val_loss: {:0.4f}, val_mean_absolute_error: {:0.4f}\".format(\n",
    "        len(history.history['loss']),\n",
    "        history.history[\"loss\"][-1],\n",
    "        history.history[\"mean_absolute_error\"][-1],\n",
    "        history.history[\"val_loss\"][-1],\n",
    "        history.history[\"val_mean_absolute_error\"][-1],\n",
    "    )\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Evaluate\")\n",
    "result = linear_multi_step.evaluate(multi_step_window.test)\n",
    "dict(zip(linear_multi_step.metrics_names, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (1, 54, 6)\n",
      "Output shape: (1, 1, 23)\n",
      "Epoch 1/20\n",
      "2637/2637 [==============================] - 40s 15ms/step - loss: 1.7385 - categorical_accuracy: 0.5157 - categorical_crossentropy: 1.7385 - mean_absolute_error: 0.0575 - val_loss: 0.9773 - val_categorical_accuracy: 0.7543 - val_categorical_crossentropy: 0.9773 - val_mean_absolute_error: 0.0378\n",
      "Epoch 2/20\n",
      "2637/2637 [==============================] - 38s 15ms/step - loss: 0.9402 - categorical_accuracy: 0.7617 - categorical_crossentropy: 0.9402 - mean_absolute_error: 0.0355 - val_loss: 0.8149 - val_categorical_accuracy: 0.8074 - val_categorical_crossentropy: 0.8149 - val_mean_absolute_error: 0.0315\n",
      "Epoch 3/20\n",
      "2637/2637 [==============================] - 40s 15ms/step - loss: 0.8233 - categorical_accuracy: 0.7957 - categorical_crossentropy: 0.8233 - mean_absolute_error: 0.0309 - val_loss: 0.7422 - val_categorical_accuracy: 0.8167 - val_categorical_crossentropy: 0.7422 - val_mean_absolute_error: 0.0286\n",
      "Epoch 4/20\n",
      "2637/2637 [==============================] - 39s 15ms/step - loss: 0.7520 - categorical_accuracy: 0.8116 - categorical_crossentropy: 0.7520 - mean_absolute_error: 0.0282 - val_loss: 0.7035 - val_categorical_accuracy: 0.8207 - val_categorical_crossentropy: 0.7035 - val_mean_absolute_error: 0.0273\n",
      "Epoch 5/20\n",
      "2637/2637 [==============================] - 37s 14ms/step - loss: 0.6951 - categorical_accuracy: 0.8197 - categorical_crossentropy: 0.6951 - mean_absolute_error: 0.0264 - val_loss: 0.6706 - val_categorical_accuracy: 0.8247 - val_categorical_crossentropy: 0.6706 - val_mean_absolute_error: 0.0263\n",
      "Epoch 6/20\n",
      "2637/2637 [==============================] - 35s 13ms/step - loss: 0.6557 - categorical_accuracy: 0.8254 - categorical_crossentropy: 0.6557 - mean_absolute_error: 0.0252 - val_loss: 0.6433 - val_categorical_accuracy: 0.8220 - val_categorical_crossentropy: 0.6433 - val_mean_absolute_error: 0.0250\n",
      "Epoch 7/20\n",
      "2637/2637 [==============================] - 34s 13ms/step - loss: 0.6146 - categorical_accuracy: 0.8261 - categorical_crossentropy: 0.6146 - mean_absolute_error: 0.0239 - val_loss: 0.6316 - val_categorical_accuracy: 0.8207 - val_categorical_crossentropy: 0.6316 - val_mean_absolute_error: 0.0245\n",
      "Epoch 8/20\n",
      "2637/2637 [==============================] - 41s 15ms/step - loss: 0.5796 - categorical_accuracy: 0.8383 - categorical_crossentropy: 0.5796 - mean_absolute_error: 0.0228 - val_loss: 0.6112 - val_categorical_accuracy: 0.8367 - val_categorical_crossentropy: 0.6112 - val_mean_absolute_error: 0.0230\n",
      "Epoch 9/20\n",
      "2637/2637 [==============================] - 36s 14ms/step - loss: 0.5538 - categorical_accuracy: 0.8406 - categorical_crossentropy: 0.5538 - mean_absolute_error: 0.0217 - val_loss: 0.5836 - val_categorical_accuracy: 0.8313 - val_categorical_crossentropy: 0.5836 - val_mean_absolute_error: 0.0220\n",
      "Epoch 10/20\n",
      "2637/2637 [==============================] - 41s 16ms/step - loss: 0.5325 - categorical_accuracy: 0.8478 - categorical_crossentropy: 0.5325 - mean_absolute_error: 0.0208 - val_loss: 0.5235 - val_categorical_accuracy: 0.8473 - val_categorical_crossentropy: 0.5235 - val_mean_absolute_error: 0.0208\n",
      "Epoch 11/20\n",
      "2637/2637 [==============================] - 37s 14ms/step - loss: 0.4873 - categorical_accuracy: 0.8610 - categorical_crossentropy: 0.4873 - mean_absolute_error: 0.0198 - val_loss: 0.5191 - val_categorical_accuracy: 0.8499 - val_categorical_crossentropy: 0.5191 - val_mean_absolute_error: 0.0199\n",
      "Epoch 12/20\n",
      "2637/2637 [==============================] - 39s 15ms/step - loss: 0.4514 - categorical_accuracy: 0.8712 - categorical_crossentropy: 0.4514 - mean_absolute_error: 0.0186 - val_loss: 0.5347 - val_categorical_accuracy: 0.8420 - val_categorical_crossentropy: 0.5347 - val_mean_absolute_error: 0.0196\n",
      "Epoch 13/20\n",
      "2637/2637 [==============================] - 41s 15ms/step - loss: 0.4604 - categorical_accuracy: 0.8654 - categorical_crossentropy: 0.4604 - mean_absolute_error: 0.0185 - val_loss: 0.4798 - val_categorical_accuracy: 0.8579 - val_categorical_crossentropy: 0.4798 - val_mean_absolute_error: 0.0197\n",
      "Epoch 14/20\n",
      "2637/2637 [==============================] - 39s 15ms/step - loss: 0.4197 - categorical_accuracy: 0.8826 - categorical_crossentropy: 0.4197 - mean_absolute_error: 0.0178 - val_loss: 0.4583 - val_categorical_accuracy: 0.8632 - val_categorical_crossentropy: 0.4583 - val_mean_absolute_error: 0.0181\n",
      "Epoch 15/20\n",
      "2637/2637 [==============================] - 39s 15ms/step - loss: 0.3910 - categorical_accuracy: 0.8932 - categorical_crossentropy: 0.3910 - mean_absolute_error: 0.0165 - val_loss: 0.4507 - val_categorical_accuracy: 0.8659 - val_categorical_crossentropy: 0.4507 - val_mean_absolute_error: 0.0178\n",
      "Epoch 16/20\n",
      "2637/2637 [==============================] - 39s 15ms/step - loss: 0.4040 - categorical_accuracy: 0.8769 - categorical_crossentropy: 0.4040 - mean_absolute_error: 0.0170 - val_loss: 0.4465 - val_categorical_accuracy: 0.8725 - val_categorical_crossentropy: 0.4465 - val_mean_absolute_error: 0.0176\n",
      "Epoch 17/20\n",
      "2637/2637 [==============================] - 39s 15ms/step - loss: 0.3613 - categorical_accuracy: 0.8964 - categorical_crossentropy: 0.3613 - mean_absolute_error: 0.0155 - val_loss: 0.4079 - val_categorical_accuracy: 0.8738 - val_categorical_crossentropy: 0.4079 - val_mean_absolute_error: 0.0164\n",
      "Epoch 18/20\n",
      "2637/2637 [==============================] - 39s 15ms/step - loss: 0.3533 - categorical_accuracy: 0.8945 - categorical_crossentropy: 0.3533 - mean_absolute_error: 0.0150 - val_loss: 0.3972 - val_categorical_accuracy: 0.8858 - val_categorical_crossentropy: 0.3972 - val_mean_absolute_error: 0.0161\n",
      "Epoch 19/20\n",
      "2637/2637 [==============================] - 39s 15ms/step - loss: 0.3316 - categorical_accuracy: 0.9032 - categorical_crossentropy: 0.3316 - mean_absolute_error: 0.0146 - val_loss: 0.4460 - val_categorical_accuracy: 0.8725 - val_categorical_crossentropy: 0.4460 - val_mean_absolute_error: 0.0176\n",
      "Epoch 20/20\n",
      "2637/2637 [==============================] - 40s 15ms/step - loss: 0.3540 - categorical_accuracy: 0.8957 - categorical_crossentropy: 0.3540 - mean_absolute_error: 0.0151 - val_loss: 0.3953 - val_categorical_accuracy: 0.8871 - val_categorical_crossentropy: 0.3953 - val_mean_absolute_error: 0.0153\n",
      "Note that these are the LAST model metrics and not the BEST model metrics because of early stopping with restore_best_weights \n",
      "epochs: 20, loss: 0.3094, mean_absolute_error: 0.0140, val_loss: 0.3953, val_mean_absolute_error: 0.0153\n",
      "Evaluate\n",
      "376/376 [==============================] - 1s 3ms/step - loss: 0.3969 - categorical_accuracy: 0.8856 - categorical_crossentropy: 0.3969 - mean_absolute_error: 0.0148\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.39688539505004883,\n",
       " 'categorical_accuracy': 0.8856382966041565,\n",
       " 'categorical_crossentropy': 0.39688539505004883,\n",
       " 'mean_absolute_error': 0.014796498231589794}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_output_nodes = len(multi_step_window.label_columns_indices)\n",
    "\n",
    "rnn = tf.keras.Sequential([\n",
    "    tf.keras.layers.LSTM(64),\n",
    "    tf.keras.layers.Dense(units=n_output_nodes, activation='softmax'),\n",
    "    # Add back the time dimension.\n",
    "    # Shape: (outputs) => (1, outputs)\n",
    "    tf.keras.layers.Reshape([1, -1]),\n",
    "])\n",
    "print('Input shape:', multi_step_window.example[0].shape)\n",
    "print('Output shape:', rnn(multi_step_window.example[0]).shape)\n",
    "\n",
    "# Train the model\n",
    "history = compile_and_fit(rnn, multi_step_window, verbose=1)\n",
    "\n",
    "print('Note that these are the LAST model metrics and not the BEST model metrics because of early stopping with restore_best_weights ')\n",
    "print(\n",
    "    \"epochs: {}, loss: {:0.4f}, mean_absolute_error: {:0.4f}, val_loss: {:0.4f}, val_mean_absolute_error: {:0.4f}\".format(\n",
    "        len(history.history['loss']),\n",
    "        history.history[\"loss\"][-1],\n",
    "        history.history[\"mean_absolute_error\"][-1],\n",
    "        history.history[\"val_loss\"][-1],\n",
    "        history.history[\"val_mean_absolute_error\"][-1],\n",
    "    )\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Evaluate\")\n",
    "result = rnn.evaluate(multi_step_window.test)\n",
    "dict(zip(rnn.metrics_names, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get last window\n",
    "def predict_new_pitches(model, n=100):\n",
    "    last_window = None\n",
    "    last_pitch = None\n",
    "    last_duration = None\n",
    "    all_predicted_pitches = []\n",
    "    all_probs = []\n",
    "\n",
    "    for i in range(n):\n",
    "        if last_window is None:\n",
    "            # Use an iterator to get the last window of the dataset. \n",
    "            for last_window, labels in multi_step_window.test_no_shuffle.as_numpy_iterator():\n",
    "                pass\n",
    "\n",
    "#             print('window:', type(last_window),last_window ,'\\n====\\nlabels', labels)\n",
    "#             print('window shape:', last_window.shape, ' label shape:', labels.shape)\n",
    "        \n",
    "        # Model is expecting a shape of (batch, timestep, features) but for one sample this is (6,6)\n",
    "        # Add dimension to input\n",
    "        probabilities = model.predict(np.array([last_window]))[0]\n",
    "        probabilities = probabilities[0]\n",
    "        all_probs.append(probabilities)\n",
    "        \n",
    "        predicted_pitch = get_pitch_from_probability(\n",
    "            probabilities,\n",
    "            key=multi_step_window.pitch_conversion_key,\n",
    "            method=SelectionMethod.PROB, n=10,\n",
    "        )\n",
    "        all_predicted_pitches.append(predicted_pitch)\n",
    "        features = get_pitch_features(predicted_pitch)\n",
    "\n",
    "        if last_pitch is None:\n",
    "            last_pitch = get_voice(VOICE)[-1]\n",
    "\n",
    "        # - find new duration based on previous and current pitch\n",
    "        if last_pitch == predicted_pitch:\n",
    "            if last_duration is None:\n",
    "                duration = multi_step_window.df.iloc[-1][\"dur\"] + 1   # bug .\n",
    "            else:\n",
    "                duration = last_duration + 1\n",
    "        else:\n",
    "            duration = 1\n",
    "\n",
    "        last_duration = duration\n",
    "        last_pitch = predicted_pitch\n",
    "\n",
    "        # create new dataframe\n",
    "        new_df = pd.DataFrame(data={\"dur\": duration}, dtype=float, index=[0])\n",
    "        (\n",
    "            new_df[\"log_pitch\"],\n",
    "            new_df[\"chroma_x\"],\n",
    "            new_df[\"chroma_y\"],\n",
    "            new_df[\"c5_x\"],\n",
    "            new_df[\"c5_y\"],\n",
    "        ) = features\n",
    "        # - Normalise features\n",
    "        new_df = (new_df - multi_step_window.mean_df) / multi_step_window.std_df\n",
    "        # - Make new window based on previous timesteps with a slide of 1 and the normalised features\n",
    "        last_window = np.append(last_window[1:], new_df.values.tolist(), axis=0)\n",
    "    return all_predicted_pitches, all_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[54, 54, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 50, 50, 49, 49, 47, 47, 50, 50, 50, 50, 50, 50, 49, 49, 47, 47, 49, 52, 52, 52, 52, 52, 52, 52, 52, 50, 50, 50, 50, 49, 49, 47, 47, 45, 45, 49, 49, 50, 50, 52, 52, 50, 50, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 50, 50, 50, 50, 50, 50, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 49, 49, 50, 50, 47, 47, 49, 49, 50, 50, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 54, 54, 54, 42, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52]\n",
      "[0.0000000e+00 0.0000000e+00 1.5482565e-05 6.1488703e-05 1.0288698e-05\n",
      " 0.0000000e+00 1.3699299e-07 8.0668753e-05 1.6363971e-07 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 1.7812812e-05 2.9502349e-05 9.7715633e-07 4.5014761e-07\n",
      " 4.3221444e-06 2.4574260e-06 8.7363023e-06]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.00023248768951589227"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions, probs = predict_new_pitches(rnn, n=400)\n",
    "print(predictions)\n",
    "print(probs[-1])\n",
    "sum(probs[-1])\n",
    "# wg = WindowGenerator(input_width=6, label_width=1, shift=1, batch_size=1)\n",
    "# print(f'train {sum(1 for _ in wg.train)} val {sum(1 for _ in wg.val)} test {sum(1 for _ in wg.test)} ')\n",
    "# print(f'full dataset {sum(1 for _ in wg.full_dataset)}')\n",
    "# print(f'data size {wg.df.shape[0]} | file voice size: {len(get_voice(0))}')\n",
    "\n",
    "# max(get_voice(2))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
